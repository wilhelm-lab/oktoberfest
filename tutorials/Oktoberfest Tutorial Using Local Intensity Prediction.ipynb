{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Oktoberfest\n",
    "\n",
    "This notebook walks you through the main workflows in Oktoberfest similar to `Oktoberfest Tutorial.ipynb`, however, instead of performing rescoring using a pre-trained intensity predictor, automatic refinement/transfer learning is performed on the dataset locally and the resulting predictor used for intensity prediction in rescoring.\n",
    "\n",
    "File download and pre-processing take about 25 minutes, while the automatic refinement/transfer learning in the rescoring step can take multiple hours depending on the machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Import necessary python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from oktoberfest.runner import run_job\n",
    "import json\n",
    "import urllib.request\n",
    "import shutil\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Download example files required to run different tasks from Zenodo \n",
    "\n",
    "The data used in this tutorial is provided in a public Zenodo record. \n",
    "This is a larger dataset with 2.55GB in total. Download time should be ~15mins (average 3 MB/s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A - Get the current directory and set the file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "download_dir = os.getcwd()\n",
    "download_file = os.path.join(download_dir, 'Oktoberfest_input.zip')\n",
    "url = 'https://zenodo.org/record/7613029/files/Oktoberfest_input.zip'\n",
    "\n",
    "download = True  # set this to false if you already have the file and don't want to download again in the next step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B - Download and extract files from Zenodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if download:\n",
    "    with tqdm(unit=\"B\", total=2739196307, unit_scale=True, unit_divisor=1000, miniters=1, desc=url.split(\"/\")[-1]) as t:\n",
    "        urllib.request.urlretrieve(url=url, filename=download_file, reporthook=lambda blocks, block_size, _: t.update(blocks * block_size - t.n))\n",
    "    shutil.unpack_archive(download_file, download_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C - Check downloaded files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_dir = download_file[:-4]\n",
    "print(f'Downloaded data is stored in {input_dir}\\nContents:')\n",
    "os.listdir(input_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Running Oktoberfest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A - Preprocessing\n",
    "\n",
    "This will read the raw files, convert them to mzML, and load the search results. While the job type is `\"CollisionEnergyCalibration\"`, actual CE calibration is skipped so the intensity predictor is not just trained using one single value for it.\n",
    "This should take around 5 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate config file\n",
    "\n",
    "Note the `\"intensity\": \"baseline\"` in `\"models\"` (line 12). This tells Oktoberfest to perform local refinement/transfer learning on a baseline intensity predictor and use it for rescoring instead of using a pre-trained one provided through Koina. Alternatively, a path to another pre-trained intensity predictor could be provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "task_config_preprocessing = {\n",
    "    \"type\": \"CollisionEnergyCalibration\",\n",
    "    \"tag\": \"\",\n",
    "    \"inputs\":{\n",
    "        \"search_results\": input_dir + \"/msms.txt\",\n",
    "        \"search_results_type\": \"Maxquant\",\n",
    "        \"spectra\": input_dir,\n",
    "        \"spectra_type\": \"raw\"\n",
    "    },\n",
    "    \"output\": \"./out\",\n",
    "    \"models\": {\n",
    "        \"intensity\": \"baseline\",\n",
    "        \"irt\": \"Prosit_2019_irt\"\n",
    "    },\n",
    "    \"prediction_server\": \"koina.wilhelmlab.org:443\",\n",
    "    \"ssl\": True,\n",
    "    \"thermoExe\": \"ThermoRawFileParser.exe\",\n",
    "    \"massTolerance\": 20,\n",
    "    \"unitMassTolerance\": \"ppm\",\n",
    "    \"numThreads\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save config as json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('./preprocessing_config.json', 'w') as fp:\n",
    "    json.dump(task_config_preprocessing, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run preprocessing job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_job(\"./preprocessing_config.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B - Refinement/Transfer Learning & Rescoring\n",
    "\n",
    "In this step, a training dataset in Parquet format is generated and used to run automtaic refinement/transfer learning of the intensity predictor specified by the user.\n",
    "After successful completion of the learning process, a training report is generated and saved in the `results/dlomix/` subdirectory of your output folder in Jupyter notebook and HTML format.\n",
    "Finally, the refined model is used for intensity prediction in Oktoberfest's rescoring step.\n",
    "Depending on your machine, this might take a couple hours. The training results are cached so the refined intensity predictor can be re-used in additional rescoring runs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate config file\n",
    "\n",
    "Note the `\"dlomixInferenceBatchSize`\" key (line 24), as well as the `\"refinementLearningOptions\"` (line 25-33) provided. All of these are set to their default values, which have been found to provide the best balance between training time and performance in practice.\n",
    "If `\"improveFurther`\" was set to `true`, an additional training phase with a reduced learning rate is performed to achieve the best possible performance at the expense of a longer training duration. This is skipped for time's sake in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "task_config_rescoring = {\n",
    "    \"type\": \"Rescoring\",\n",
    "    \"tag\": \"\",\n",
    "    \"inputs\":{\n",
    "        \"search_results\": input_dir + \"/msms.txt\",\n",
    "        \"search_results_type\": \"Maxquant\",\n",
    "        \"spectra\": input_dir,\n",
    "        \"spectra_type\": \"raw\"\n",
    "    },\n",
    "    \"output\": \"./out\",\n",
    "    \"models\": {\n",
    "        \"intensity\": \"baseline\",\n",
    "        \"irt\": \"Prosit_2019_irt\"\n",
    "    },\n",
    "    \"prediction_server\": \"koina.wilhelmlab.org:443\",\n",
    "    \"ssl\": True,\n",
    "    \"thermoExe\": \"ThermoRawFileParser.exe\",\n",
    "    \"numThreads\": 4,\n",
    "    \"fdr_estimation_method\": \"percolator\",  # ensure percolator is installed on your system\n",
    "    \"regressionMethod\": \"spline\",\n",
    "    \"allFeatures\": False,\n",
    "    \"massTolerance\": 20,\n",
    "    \"unitMassTolerance\": \"ppm\",\n",
    "    \"dlomixInferenceBatchSize\": 1024,\n",
    "    \"refinementLearningOptions\": {\n",
    "        \"batchSize\": 1024,\n",
    "        \"includeOriginalSequences\": false,\n",
    "        \"improveFurther\": false,\n",
    "        \"datasetFilteringOptions\": {\n",
    "            \"searchEngineScoreThreshold\": 0,\n",
    "            \"numDuplicates\": 100\n",
    "        }\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save config as json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('./rescoring_config.json', 'w') as fp:\n",
    "    json.dump(task_config_rescoring, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run rescoring job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_job(\"rescoring_config.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
