{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oktoberfest Rescoring API Tutorial\n",
    "\n",
    "This notebook covers how to run Oktoberfest Rescoring by using API functions. All API functions as well as additional guides and examples can be found on the official read the docs page at https://oktoberfest.readthedocs.io/en/stable/index.html.\n",
    "\n",
    "The workflow is divided into six sections:\n",
    "\n",
    "1. Install Oktoberfest and load packages\n",
    "2. Download example data\n",
    "3. Preprocess search results and spectra files\n",
    "4. Annotate spectra and calibrate collision energy\n",
    "5. Predict intensities and indexed retention time\n",
    "6. Rescore with percolator\n",
    "7. Plot and interpret the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Installation\n",
    "\n",
    "Before using Oktoberfest, the package and dependencies need to be installed. This step is only required once on the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 \n",
    "Install percolator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/percolator/percolator/releases/download/rel-3-06-01/percolator-v3-06-linux-amd64.deb\n",
    "!dpkg -i percolator-v3-06-linux-amd64.deb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the install fails due to missing superuser privilages, run this command instead. You will be prompted for your superuser password."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "password = str(getpass.getpass()) \n",
    "!echo '{password}' | sudo -S bash -c 'dpkg -i percolator-v3-06-linux-amd64.deb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Oktoberfest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q oktoberfest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required packages and functions by executing the code in the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import oktoberfest as ok\n",
    "from oktoberfest import __version__ as version\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import urllib.request\n",
    "import requests\n",
    "import shutil\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this works, you have installed Oktoberfest correctly. You check the version of your installed oktoberfest instance by executing the following. (This notebook was tested with Oktoberfest version 0.7.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Download example data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data used in this notebook as an example is provided as a zip archive that can be downloaded from zenodo from this record https://zenodo.org/records/10814834. In case you want to use your own data, skip ahead to Step 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the download link as well as file name and download destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://zenodo.org/records/10814834/files/tomato_dataset_example.zip\"  # download link\n",
    "download_dir = Path(\"./data\")                                                 # choose any directory\n",
    "file_name = Path(\"tomato_dataset_example.zip\")                                # choose any filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and unpack the data. (2.74G, approx. 5 minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(download_dir):\n",
    "  os.mkdir(download_dir)\n",
    "download_file = os.path.join(download_dir, file_name)\n",
    "filesize = int(requests.head(url).headers.get('content-length', -1))\n",
    "with tqdm(unit=\"B\", total=filesize, unit_scale=True, unit_divisor=1000, miniters=1, desc=url.split(\"/\")[-1]) as t:\n",
    "    urllib.request.urlretrieve(url=url, filename=download_file, reporthook=lambda blocks, block_size, _: t.update(blocks * block_size - t.n))\n",
    "shutil.unpack_archive(download_file, download_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Spectral preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Converting raw files\n",
    "If your spectra data is saved in form of .raw files, you need to convert them to .mzml files in order to perform rescoring. In the case that they are already in the mzml data format you can skip to step B). Since Oktoberfest uses the ThermoRawFileParser to convert the files, you need to make sure that you have installed 'mono' and give Oktoberfest the path to the executable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install mono if needed. Installation may differ by Linux distribution, refer to https://www.mono-project.com/download/stable/#download-lin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "password = getpass.getpass()\n",
    "!echo '{password}' | sudo -S bash -c 'apt install mono-complete -y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the ThermoRawFileParser executable\n",
    "therm = Path(\"/opt/compomics/ThermoRawFileParser.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a list of all raw files located in the specified input directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_spectra = ok.pp.list_spectra(download_dir / file_name.stem,'raw')\n",
    "print(list_of_spectra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the raw files to mzml files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output directory where individual mzML files will be stored\n",
    "mzml_directory = download_dir / \"mzml/\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(mzml_directory):\n",
    "    os.makedirs(mzml_directory)\n",
    "\n",
    "# Initialize an empty list to store the paths of the converted mzML files\n",
    "conversion_results = []\n",
    "\n",
    "# Loop through the list of spectra files and convert each one\n",
    "for file in list_of_spectra:\n",
    "    # Generate corresponding mzML file name for each raw file\n",
    "    base_filename = os.path.splitext(os.path.basename(file))[0]  # Remove file extension\n",
    "    output_mzml_file = os.path.join(mzml_directory, f\"{base_filename}.mzML\")\n",
    "    \n",
    "    # Call the convert_spectra function with the current file and the output file path\n",
    "    ok.pp.convert_raw_to_mzml(file, output_file=output_mzml_file, thermo_exe=therm)\n",
    "    \n",
    "    # Append the path of the converted mzML file to the conversion_results list\n",
    "    conversion_results.append(output_mzml_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Loading Spectra\n",
    "Specify the mzml path and list all mzml files in directory. In case you are using your own data, you need to change the mzml_dir variable to the path of your own mzml directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mzml_directory = download_dir / \"tomato_dataset_example\" # change if needed\n",
    "mzml_list = ok.pp.list_spectra(mzml_directory,'mzml')\n",
    "print(mzml_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have multiple spectra files, load them all separately and save them to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra_list = []\n",
    "for spectra_file in mzml_list:\n",
    "    spectra = ok.pp.load_spectra(filenames=spectra_file, parser=\"pyteomics\")\n",
    "    spectra_list.append(spectra)\n",
    "print(spectra_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Loading search results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting search results to internal Oktoberfest format. If you are using custom search results, this step isn't necessairy as they should already be provided in the internal data format. Please refer to https://oktoberfest.readthedocs.io/en/stable/internal_format.html for the specific format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output directory for the converted search results\n",
    "search_path = Path('./out/msms/msms.prosit')\n",
    "\n",
    "# Create the directoriy if it doesn't exist\n",
    "if not os.path.exists(search_path.parent):\n",
    "    os.makedirs(search_path.parent)\n",
    "\n",
    "# conveerting maxquant msms.txt to internal format\n",
    "ok.pp.convert_search(input_path= download_dir / \"tomato_dataset_example/msms.txt\", output_file=search_path, search_engine='maxquant')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading search results to a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peptide_df = ok.pp.load_search(search_path)\n",
    "peptide_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering search results using given peptide length and charge requirements posed by the selected model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_peptides = ok.pp.filter_peptides_for_model(peptides=peptide_df, model='prosit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Annotate spectra and calibrate collision energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotation and collision energy calibration is done seperately for each raw file so you need to loop over all spectra files in the spectra_list. \n",
    "The spectra files need to be merged on \"Raw_file\" and \"Scan number\" with the peptides taken from the search results before annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psm_list = []\n",
    "for spectra in spectra_list:\n",
    "    psms = ok.pp.merge_spectra_and_peptides(spectra=spectra, search=filtered_peptides)\n",
    "    psm_list.append(psms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotate the peaks for all psms in each psm_file (by efault b- and y-ions). It is important to check the mass_tolerance of the data used in order to correctly set the mass_tol and unit_mass_toll parameters. More information can be found in the docs https://oktoberfest.readthedocs.io/en/stable/config.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library_list = []\n",
    "for psms in psm_list:\n",
    "    library = ok.pp.annotate_spectral_library(psms=psms, mass_tol=20, unit_mass_tol='ppm')\n",
    "    library_list.append(library)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform ce_calibration on each annotated library with the intended model and ce range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment_list = []\n",
    "for library in library_list:\n",
    "    alignment_library = ok.pr.ce_calibration(library, ce_range=(19,50),group_by_charge=False,model_name=\"Prosit_2020_intensity_HCD\",  \n",
    "                  server_url=\"koina.wilhelmlab.org:443\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine and assign the best collision energy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for library in library_list:\n",
    "    ce_alignment = alignment_library.obs.groupby(by=[\"COLLISION_ENERGY\"])[\"SPECTRAL_ANGLE\"].mean()\n",
    "    best_ce = ce_alignment.idxmax()\n",
    "    library.obs['COLLISION_ENERGY'] = best_ce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Predict intensities and indexed retention time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for library in library_list:\n",
    "    ok.pr.predict_rt(data = library, server_url=\"koina.wilhelmlab.org:443\", model_name=\"Prosit_2019_irt\", ssl=True)\n",
    "    ok.pr.predict_intensities(data=library, server_url=\"koina.wilhelmlab.org:443\", model_name=\"Prosit_2020_intensity_HCD\", ssl=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Rescore with percolator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create output dictionary for percolator results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percolator_dir = Path('./out/percolator')\n",
    "\n",
    "if not os.path.exists(percolator_dir):\n",
    "    os.makedirs(percolator_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two feature files for each spectra files that will serve as input for percolator. The original file containing only original features from the search results as well as the rescore file containing additional features calculated by Oktoberfest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists to save feature files in order to merge them into one later\n",
    "rescore_files = []\n",
    "original_files = []\n",
    "\n",
    "for library, spectra_file in zip(library_list,mzml_list):\n",
    "    # create output paths for feature files\n",
    "    original_features = percolator_dir / spectra_file.with_suffix(\".original.tab\").name\n",
    "    original_files.append(original_features)\n",
    "    rescore_features = percolator_dir / spectra_file.with_suffix(\".rescore.tab\").name\n",
    "    rescore_files.append(rescore_features)\n",
    "\n",
    "    # generate features for original file \n",
    "    ok.re.generate_features(library=library, search_type='original', output_file=original_features, all_features=False, regression_method='spline')\n",
    "    # generate features for rescore file \n",
    "    ok.re.generate_features(library=library, search_type='rescore', output_file=rescore_features, all_features=False, regression_method='spline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge all feature files into one combined original and one combined rescore file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_rescore = percolator_dir / \"rescore.tab\"\n",
    "ok.re.merge_input(rescore_files, merged_rescore)\n",
    "\n",
    "merged_original = percolator_dir / \"original.tab\"\n",
    "ok.re.merge_input(original_files, merged_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rescore with percolator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.re.rescore_with_percolator(merged_rescore, percolator_dir)\n",
    "ok.re.rescore_with_percolator(merged_original, percolator_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots path \n",
    "plots = Path('./out/plots')\n",
    "\n",
    "# Generate histogram of the score distribution for targets and decoys.\n",
    "peptide_decoy_df = pd.read_csv(percolator_dir / 'rescore.percolator.decoy.peptides.txt', sep='\\t')\n",
    "\n",
    "peptide_target_df = pd.read_csv(percolator_dir / 'rescore.percolator.peptides.txt', sep='\\t')\n",
    "\n",
    "display(peptide_decoy_df)\n",
    "\n",
    "ok.pl.plot_score_distribution(peptide_target_df, peptide_decoy_df, level = 'peptide', filename=plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.pl.plot_all(percolator_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
