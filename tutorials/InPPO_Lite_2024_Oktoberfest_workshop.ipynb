{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4RyWlO0elRo"
      },
      "source": [
        "# Oktoberfest Workshop\n",
        "\n",
        "This notebook is prepared to be run in Google [Colaboratory](https://colab.research.google.com/).\n",
        "\n",
        "This notebook contains tasks that are designed to guide new users through the following topics:\n",
        "\n",
        "1. How to install oktoberfest and load packages\n",
        "2. How to get the required data\n",
        "3. How to prepare a configuration file\n",
        "4. How to run a job and interpret the output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr-3HR_3Dymy"
      },
      "source": [
        "# 1. Installation\n",
        "\n",
        "Before using Oktoberfest, the package and dependencies need to be installed. This step is only required once on your notebook, but it may need to be repeated in Google Collab.\n",
        "\n",
        "## Task 1.1\n",
        "\n",
        "What are the requirements for Oktoberfest and where do you find this information? (Hint: Search the Oktoberfest documentation at readthedocs using your favourite search engine).\n",
        "\n",
        "## Task 1.2\n",
        "\n",
        "Execute the below code cell, which installs percolator and Oktoberfest and restart the session if asked."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYBkB4ygeMNP"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/percolator/percolator/releases/download/rel-3-06-01/percolator-v3-06-linux-amd64.deb\n",
        "!dpkg -i percolator-v3-06-linux-amd64.deb\n",
        "!pip install -q oktoberfest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5-R5ogFtNge"
      },
      "source": [
        "For this notebook to work, a few packages need to be imported that provide the functions used in the following. Shouly you get an error here, check that installation of the required packages was successful.\n",
        "\n",
        "## Task 1.3\n",
        "\n",
        "Import the below packages and functions by executing the code in the cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhIY7CQueku_"
      },
      "outputs": [],
      "source": [
        "from oktoberfest.runner import run_job\n",
        "from oktoberfest import __version__ as version\n",
        "import os\n",
        "import json\n",
        "import urllib.request\n",
        "import requests\n",
        "import shutil\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I91JIxGPGUql"
      },
      "source": [
        "If this works, you have installed Oktoberfest correctly.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1.4\n",
        "How can you check that you are using the current stable version? (check the output of __version__ using the below code cell and the Oktoberfest documentation)"
      ],
      "metadata": {
        "id": "nvIUMRlF5gtW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RM3nbzjGGGK"
      },
      "outputs": [],
      "source": [
        "version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPB8spZ8gCiP"
      },
      "source": [
        "# Task 2: Getting the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJz0mVfKgHt7"
      },
      "source": [
        "The data used in this notebook is provided as a zip archive that can be downloaded from zenodo from this record https://zenodo.org/records/10793943\n",
        "\n",
        "## Task 2.1\n",
        "\n",
        "Find the download link in the public zenodo record. You can copy the link by hovering over the download button, click your right mouse button and choose the option to copy the download link.\n",
        "\n",
        "## Task 2.2\n",
        "\n",
        "Define variables for the download link, URL, and the local file name using the below code cell and execute the cell afterwards.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eulzl9fOgKZs"
      },
      "outputs": [],
      "source": [
        "url = \"https://zenodo.org/records/10814834/files/tomato_dataset_example.zip\"                   # here goes the download link of the file to download from the zenodo record, it should look like \"https://zenodo.org/records/10793943/...\", make sure to include the \"\"\n",
        "download_dir = \"Oktoberfest_input/\"          # you can choose any directory, e.g. \"Oktoberfest_input/\", make sure to include the \"\"\n",
        "file_name = \"tomato_dataset_example.zip\"             # you can choose any filename, e.g. \"sample_data.zip\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gtbcdaoskvq"
      },
      "source": [
        "## Task 2.3\n",
        "\n",
        "Download and unpack the data using the below code cell. You should see a progress bar while it is downloading the file (86MB, approx. 1 minute)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgxrLYTzsk3-"
      },
      "outputs": [],
      "source": [
        "if not os.path.isdir(download_dir):\n",
        "  os.mkdir(download_dir)\n",
        "download_file = os.path.join(download_dir, file_name)\n",
        "filesize = int(requests.head(url).headers.get('content-length', -1))\n",
        "with tqdm(unit=\"B\", total=filesize, unit_scale=True, unit_divisor=1000, miniters=1, desc=url.split(\"/\")[-1]) as t:\n",
        "    urllib.request.urlretrieve(url=url, filename=download_file, reporthook=lambda blocks, block_size, _: t.update(blocks * block_size - t.n))\n",
        "shutil.unpack_archive(download_file, download_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCpLdxnuK9f7"
      },
      "source": [
        "## Task 2.4\n",
        "\n",
        "Check that the download was successful. Hint: Use the file browser on the left side to search for the folder you defined using the __download_dir__ variable above and check the content.  What do you find here?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sw6EevVMnVRR"
      },
      "source": [
        "# Task 3: Rescoring with Oktoberfest\n",
        "\n",
        "The main feature of oktoberfest is to perform rescoring. This requires two main inputs:\n",
        "- unfiltered search results, for MaxQuant, this would mean a run with 100% PSM and peptide FDR\n",
        "- get spectra, either in ThermoFisher .RAW, Bruker .d, or mzML format\n",
        "\n",
        "In addition, Oktoberfest can get predictions from various data dependent models, that are provided by a Koina instance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnWbSve1gLpb"
      },
      "source": [
        "## Task 3.1\n",
        "\n",
        "Where do you find information about the configuration options, example configurations, and the supported prediction models (Hint: Check the [Usage principles](https://oktoberfest.readthedocs.io/en/latest/usage.html) in the Oktoberfest documentation)? Define below variables accordingly.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HN7YqI6pOhaD"
      },
      "outputs": [],
      "source": [
        "spectra = \"Oktoberfest_input/tomato_dataset_example/5407_GC4_063119_S00_U4_R1.mzML\"               # this is the location of the mzML file containing the measured spectra, i.e. \"<your download_dir>/<filename>.mzml\"\n",
        "spectra_type =  \"mzml\"         # this is the format the spectra are provided in (\"mzml\", \"RAW\", \"d\"), which one is correct here?\n",
        "\n",
        "search_results = \"Oktoberfest_input/tomato_dataset_example/msms.txt\"        # this is the location of the search engine output, i.e. \"<your download_dir>/<search_engine output>\"\n",
        "search_results_type = \"maxquant\"   # this is the name of the search engine that produced the search results, which is the correct search engine here?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBa27_d5gSpV"
      },
      "source": [
        "## Task 3.2\n",
        "\n",
        "The data we are working with here was aquired using beam-type collision induced dissociation (HCD) without tandem mass tags (TMT).\n",
        "\n",
        "Which are the models to use for fragment intensity prediction and retention time prediction and the server URL that provides access to these models (Hint: Check the [Usage principles](https://oktoberfest.readthedocs.io/en/latest/usage.html) in the Oktoberfest documentation)?\n",
        "\n",
        "Also specify the directory you want to store all the outputs from Oktoberfest in."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQEFvoOxgTuE"
      },
      "outputs": [],
      "source": [
        "intensity_model =  \"Prosit_2020_intensity_HCD\"      # this is the model used for fragment intensity prediction, e.g. \"some model\"\n",
        "retention_time_model = \"Prosit_2019_irt\"  # this is the model used for retention time prediction, e.g. \"some model\"\n",
        "prediction_server =  \"koina.wilhelmlab.org:443\"    # the Koina server that provides access to the specified models, e.g. \"<url>:<port number>\"\n",
        "\n",
        "output_directory = \"rescore_out\"      # this is the output folder for everything Oktoberfest produces during rescoring, e.g. \"rescore_out\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17D9Zkb4xEU3"
      },
      "source": [
        "## Task 3.3\n",
        "\n",
        "Save the variables you have defined above in the below configuration and store it to disk. For simplicity, this is providing a minimal configuration for this task, so you can simply execute the code cell.\n",
        "\n",
        "A detailed explanation of all available configuration options can be found in the [Usage principles](https://oktoberfest.readthedocs.io/en/latest/usage.html) in the Oktoberfest documentation.\n",
        "\n",
        "What are the mass tolerance and unit variables for?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJWBZP1fgiXL"
      },
      "outputs": [],
      "source": [
        "task_config_rescoring = {\n",
        "    \"type\": \"Rescoring\",\n",
        "    \"inputs\":{\n",
        "        \"search_results\": search_results,\n",
        "        \"search_results_type\": search_results_type,\n",
        "        \"spectra\": spectra,\n",
        "        \"spectra_type\": spectra_type\n",
        "    },\n",
        "    \"output\": output_directory,\n",
        "    \"models\": {\n",
        "        \"intensity\": intensity_model,\n",
        "        \"irt\": retention_time_model\n",
        "    },\n",
        "    \"prediction_server\": prediction_server,\n",
        "    \"ssl\": True,\n",
        "    \"numThreads\": 1,\n",
        "    \"fdr_estimation_method\": \"percolator\",\n",
        "    \"massTolerance\": 20,\n",
        "    \"unitMassTolerance\": \"ppm\"\n",
        "}\n",
        "\n",
        "# this is for storing the file on disk\n",
        "with open('./rescoring_config.json', 'w') as fp:\n",
        "    json.dump(task_config_rescoring, fp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7TJIKwljrOV"
      },
      "source": [
        "(Optional) You can now check the configuration file on disk, to see if it looks correctly by finding it with the file browser on the left.\n",
        "\n",
        "The oktoberfest documentation provides [example configurations](https://oktoberfest.readthedocs.io/en/latest/jobs.html#c-rescoring) that show you how a typical rescoring run for MaxQuant is set up with all the available options.\n",
        "\n",
        "If you want to get detailed information about individual options and allowed values, you can check the documentation for the [full configuration](https://oktoberfest.readthedocs.io/en/latest/config.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPZcc7qlkC9w"
      },
      "source": [
        "## Task 3.4\n",
        "\n",
        "Start the rescoring run.\n",
        "\n",
        "After preparation of the configuration file, oktoberfest can be instructed to run a job with the provided configuration file. This step may take a while (approx. 3-5 minutes) and provide you with log output that tracks the progress of rescoring.\n",
        "Oktoberfest will perform the following steps:\n",
        "\n",
        "- read the search results from maxquant and translate them to the internal format used by Oktoberfest. The specification for this format can be found in the documentation.\n",
        "- parse the mzml data to retreive MS2 spectra, then merge with the search results to generate PSMs, filtering out spectra without a search result\n",
        "- annotation of spectra for all y- and b-fragments in charge states 1-3\n",
        "- perform a normalized collision energy (NCE) calibration using the top 1000 highest scoring target PSMs, to determine the NCE for which the highest spectral angle can be achieved\n",
        "- fragment intensity and retention time prediction for all PSMs\n",
        "- retention time alignment, spectral angle and further feature calculation for rescoring using percolator\n",
        "- rescoring using features from intensity and retention time prediction and the original search engine score\n",
        "- plotting summaries of the rescoring run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_OsKhWZmeP1"
      },
      "outputs": [],
      "source": [
        "run_job(\"./rescoring_config.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Odldu8aDms4f"
      },
      "source": [
        "## Task 3.5\n",
        "\n",
        "Explore the output folder of Oktoberfest using the file brwoser on the left.\n",
        "\n",
        "Where do you find information about the output folder structure and what you can find where (Hint: Check the [Usage principles](https://oktoberfest.readthedocs.io/en/latest/usage.html) in the Oktoberfest documentation)?\n",
        "\n",
        "Did rescoring work and provide better results (Results discussion follows)?\n",
        "\n",
        "You can use the following code cell to create a zip file of the Oktoberfest output folder you specified, then download the zip file \"oktoberfest.zip\" for easy exploration:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcJ_6GHeYr_R"
      },
      "outputs": [],
      "source": [
        "!zip -r \"oktoberfest.zip\" $output_directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhjmB4tkvewX"
      },
      "source": [
        "# Task 4: Re-creating protein groups\n",
        "\n",
        "After rescoring the data, we need to re-assemble the peptides to protein groups. To do so, we can use [Picked Group FDR](https://github.com/kusterlab/picked_group_fdr) python package that is one of the most sophisticated solutions for this purpose.\n",
        "\n",
        "For more informtion and usage principle, please check out Picked Group FDR's [readthedocs](https://picked-group-fdr.readthedocs.io/en/latest/) page.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 4.1\n",
        "\n",
        "Installing the Picked Group FDR package from the deveopment branch of its GitHub repository."
      ],
      "metadata": {
        "id": "rSx4LIE04blw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ll72DbDv-5u"
      },
      "outputs": [],
      "source": [
        "# !pip install picked_group_fdr\n",
        "!git clone https://github.com/kusterlab/picked_group_fdr.git\n",
        "!pip install -q ./picked_group_fdr\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 4.2\n",
        "\n",
        "Importing the required modules."
      ],
      "metadata": {
        "id": "qdAdLKmQ4pfT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_snx4C62ObZ"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import picked_group_fdr.pipeline as picked_group_fdr\n",
        "from picked_group_fdr.digestion_params import DigestionParams"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 4.3\n",
        "\n",
        "Updating the evidence.txt file with the Oktoberfest's output."
      ],
      "metadata": {
        "id": "xZ7rEVnX4xhO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsH-TEBm2cPK"
      },
      "outputs": [],
      "source": [
        "picked_group_fdr.run_update_evidence(\n",
        "        [\"Oktoberfest_input/tomato_dataset_example/evidence.txt\"],\n",
        "        [\"rescore_out/results/percolator/rescore.percolator.psms.txt\", \"rescore_out/results/percolator/rescore.percolator.decoy.psms.txt\"],\n",
        "        [\"rescore_out/results/evidence.txt\"],\n",
        "        \"prosit\",\n",
        "        suppress_missing_peptide_warning=True\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 4.4\n",
        "\n",
        "Defining the parameters for the protein group inference."
      ],
      "metadata": {
        "id": "Oqtdmqe246tc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkrAW4xY2gtx"
      },
      "outputs": [],
      "source": [
        "digest_params = [DigestionParams(\"trypsinp\", \"full\", 7, 30, 2, \"KR\", False)]\n",
        "do_quant = True\n",
        "lfq_min_peptide_ratios = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 4.5\n",
        "\n",
        "Running the algorithm\n",
        "\n",
        "After this step you will have the new protein groups file. Be mindful that the output is not filtered for 1% FDR."
      ],
      "metadata": {
        "id": "DsyuHcPn5AnE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTOseQRD2uHk"
      },
      "outputs": [],
      "source": [
        "picked_group_fdr.run_picked_group_fdr(\n",
        "    [\"rescore_out/results/evidence.txt\"],\n",
        "    \"rescore_out/results/proteinGroups_Unfiltered.txt\",\n",
        "    [\"Oktoberfest_input/tomato_dataset_example/UP000004994.fasta\"],\n",
        "    digest_params,\n",
        "    do_quant,\n",
        "    lfq_min_peptide_ratios,\n",
        "    suppress_missing_peptide_warning=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 4.6\n",
        "\n",
        "Filtering the protein groups with 1% FDR."
      ],
      "metadata": {
        "id": "T-GwhlbL5OH5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dv0K0U9S28Hy"
      },
      "outputs": [],
      "source": [
        "picked_group_fdr.run_filter_fdr_maxquant([\"rescore_out/results/proteinGroups_Unfiltered.txt\"], \"rescore_out/results/proteinGroups_1%FDR.txt\", fdr_cutoff=0.01)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}